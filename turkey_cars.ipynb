{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, r2_score\n",
    "\n",
    "file_path = './datasets/turkey_cars.csv'\n",
    "cars_data = pd.read_csv(file_path, encoding='ISO-8859-9')\n",
    "cars_data.columns = cars_data.columns.str.replace('?', 'i')\n",
    "\n",
    "# Separate the target variable (y) from the predictors (X)\n",
    "cars_data_with_color = cars_data.copy().drop(['Fiyat'], axis=1)\n",
    "X = cars_data.drop(columns=['Fiyat', 'ilan Tarihi', 'Renk'], axis=1)\n",
    "y = cars_data['Fiyat']\n",
    "\n",
    "print(X.columns.values)\n",
    "print(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting categorical columns with relatively low cardinality for one-hot encoding\n",
    "categorical_cols = [cname for cname in X.columns if X[cname].nunique() < 100 and \n",
    "                    X[cname].dtype == \"object\" and cname not in ['ilan Tarihi', 'Renk']]\n",
    "\n",
    "# Selecting numerical columns\n",
    "numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keeping selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X = X[my_cols]\n",
    "\n",
    "print(categorical_cols)\n",
    "print(numerical_cols)\n",
    "print(X.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(X_train[0:5]['Km'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = StandardScaler()  # Data standardization with standard deviation and mean\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print(X_train_transformed.shape)\n",
    "print(X_train_transformed[0:5][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = cars_data[numerical_cols + ['Fiyat']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average price for each brand\n",
    "avg_price_per_brand = cars_data.groupby('Marka')['Fiyat'].mean()\n",
    "\n",
    "# Sort the results in descending order\n",
    "avg_price_per_brand = avg_price_per_brand.sort_values(ascending=False)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 10))\n",
    "avg_price_per_brand.plot(kind='barh')\n",
    "plt.title('Average Price per Brand')\n",
    "plt.xlabel('Average Price')\n",
    "plt.ylabel('Brand')\n",
    "plt.gca().invert_yaxis()  # invert the y-axis to have the highest value at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average price for each color\n",
    "avg_price_per_color = cars_data.groupby('Renk')['Fiyat'].mean()\n",
    "\n",
    "# Sort the results in descending order\n",
    "avg_price_per_color = avg_price_per_color.sort_values(ascending=False)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 10))\n",
    "avg_price_per_color.plot(kind='barh')\n",
    "plt.title('Average Price per Color')\n",
    "plt.xlabel('Average Price')\n",
    "plt.ylabel('Color')\n",
    "plt.gca().invert_yaxis()  # invert the y-axis to have the highest value at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each value in the 'vites' column\n",
    "vites_counts = cars_data['Vites'].value_counts()\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "vites_counts.plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Distribution of Vites')\n",
    "plt.ylabel('')  # Hide the y-axis label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST REGRESSION\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "rf.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "y_pred_rf = rf.predict(X_test_transformed)\n",
    "\n",
    "print('R2 score for RF:', r2_score(y_test, y_pred_rf))\n",
    "print('MAE for RF:', mean_absolute_error(y_test, y_pred_rf))\n",
    "print('MAPE for RF:', mean_absolute_percentage_error(y_test, y_pred_rf) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting feature importances from the model within the pipeline\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Getting the list of original feature names after one-hot encoding\n",
    "encoded_features = preprocessor.transformers_[1][1].get_feature_names_out(categorical_cols)\n",
    "feature_names = numerical_cols + list(encoded_features)\n",
    "\n",
    "# Mapping these importances back to the original feature names \n",
    "# (including aggregating importances for categories of each original categorical feature)\n",
    "importance_dict = dict(zip(feature_names, feature_importances))\n",
    "original_feature_importances = {feature: 0 for feature in my_cols}\n",
    "\n",
    "for feature, importance in importance_dict.items():\n",
    "    if feature in original_feature_importances:\n",
    "        original_feature_importances[feature] += importance\n",
    "    else:\n",
    "        original_feature_name = feature.split('_')[0]  # Extracting the original feature name before encoding\n",
    "        original_feature_importances[original_feature_name] += importance\n",
    "\n",
    "# Sorting the features by importance\n",
    "sorted_feature_importances = sorted(original_feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Converting to DataFrame for easier plotting\n",
    "df_feature_importances = pd.DataFrame(sorted_feature_importances, columns=['Feature', 'Importance'])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=df_feature_importances, palette=\"rocket\", hue='Feature')\n",
    "plt.title('Feature Importance for Predicting Car Price')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPPORT VECTOR REGRESSION\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR(kernel='linear')\n",
    "svr.fit(X_train_transformed, y_train)\n",
    "y_pred_svr = svr.predict(X_test_transformed)\n",
    "\n",
    "print('R2 score for SVR:', r2_score(y_test, y_pred_svr))\n",
    "print(f\"MAE for SVR: {mean_absolute_error(y_test, y_pred_svr)}\")\n",
    "print('MAPE for SVR:', mean_absolute_percentage_error(y_test, y_pred_svr) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR and POLYNOMIAL REGRESSION\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pr = PolynomialFeatures(degree=1)\n",
    "X_poly = pr.fit_transform(X_train_transformed)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_poly, y_train)\n",
    "X_poly_test = pr.fit_transform(X_test_transformed)\n",
    "\n",
    "y_pred_poly = lr.predict(X_poly_test)\n",
    "\n",
    "print(f\"R2 score for POLY: {r2_score(y_test, y_pred_poly)}\")\n",
    "print(f\"MAE for POLY: {mean_absolute_error(y_test, y_pred_poly)}\")\n",
    "print('MAPE for SVR:', mean_absolute_percentage_error(y_test, y_pred_poly) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR Line with Km vs Fiyat\n",
    "X_km = cars_data[['Km']].values  # Predictor\n",
    "y_fiyat = cars_data['Fiyat'].values  # Response\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_km, y_fiyat)\n",
    "\n",
    "# Generate a range of values for Km to create a prediction line\n",
    "X_km_range = np.linspace(X_km.min(), X_km.max(), 100).reshape(-1, 1)\n",
    "y_fiyat_pred = model.predict(X_km_range)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_km, y_fiyat, color='blue', label='Actual data', alpha=0.5)\n",
    "plt.plot(X_km_range, y_fiyat_pred, color='red', label='Linear regression line')\n",
    "plt.title('Km vs Fiyat with Linear Regression')\n",
    "plt.xlabel('Km')\n",
    "plt.ylabel('Fiyat')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Fit your model\n",
    "lr.fit(X_train_transformed, y_train)\n",
    "\n",
    "X_test_dense = X_test_transformed.toarray()\n",
    "print(X_test_dense.shape)\n",
    "feature_names = preprocessor.get_feature_names_out(input_features=X_train.columns)\n",
    "\n",
    "# Create a PermutationImportance object\n",
    "results = permutation_importance(lr, X_test_dense, y_test, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Get importance\n",
    "importance = results.importances_mean\n",
    "\n",
    "# Create a list of (feature, importance) tuples\n",
    "importances = list(zip(feature_names, importance))\n",
    "\n",
    "# Filter out features with nan importance\n",
    "importances = [(feature, score) for feature, score in importances if not np.isnan(score)]\n",
    "\n",
    "# Calculate the total importance\n",
    "total_importance = sum(abs(score) for feature, score in importances)\n",
    "\n",
    "# Calculate weights and create a list of (feature, weight, importance) tuples\n",
    "importances = [(feature, abs(score) / total_importance, score) for feature, score in importances]\n",
    "\n",
    "# Sort the importances by weight in descending order\n",
    "importances.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Summarize feature importance\n",
    "for feature, weight, importance in importances:\n",
    "    print('Feature: %s, Weight: %.5f, Score: %.5f' % (feature.split('__')[1], weight, importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the top 10 and bottom 10 features by weight\n",
    "top_10 = importances[:10]\n",
    "bottom_10 = importances[-10:]\n",
    "\n",
    "# Create a new figure with 2 subplots side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot the top 10 features\n",
    "axs[0].barh([x[0].split('__')[1] for x in top_10], [x[1] for x in top_10])\n",
    "axs[0].set_title('Top 10 Features')\n",
    "axs[0].invert_yaxis()\n",
    "\n",
    "# Plot the bottom 10 features\n",
    "axs[1].barh([x[0].split('__')[1] for x in bottom_10], [x[1] for x in bottom_10])\n",
    "axs[1].set_title('Bottom 10 Features')\n",
    "axs[1].invert_yaxis()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIDGE REGRESSION\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(X_train_transformed, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test_transformed)\n",
    "\n",
    "print(f\"R2 score for Ridge: {r2_score(y_test, y_pred_ridge)}\")\n",
    "print(f\"MAE for Ridge: {mean_absolute_error(y_test, y_pred_ridge)}\")\n",
    "print('MAPE for Ridge:', mean_absolute_percentage_error(y_test, y_pred_ridge) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK REGRESSION\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(8,16,32,16), activation='relu', solver='adam', max_iter=10000, random_state=42)\n",
    "mlp.fit(X_train_transformed, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test_transformed)\n",
    "\n",
    "print(f\"R2 score for MLP: {r2_score(y_test, y_pred_mlp)}\")\n",
    "print(f\"MAE for MLP: {mean_absolute_error(y_test, y_pred_mlp)}\")\n",
    "print('MAPE for MLP:', mean_absolute_percentage_error(y_test, y_pred_mlp) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(cars_data['Vites'].unique())\n",
    "\n",
    "dummy_data = {\n",
    "    'ilan Tarihi': '01/01/2020',\n",
    "    'Marka': 'Toyota',\n",
    "    'Arac Tip Grubu': 'Sedan',\n",
    "    'Arac Tip': '2.0 D-4D',\n",
    "    'Model Yil': 2015,\n",
    "    'Yakit Turu': 'Dizel',\n",
    "    'Vites': 'Yar? Otomatik Vites',\n",
    "    'CCM': '1601-1800 cc',\n",
    "    'Beygir Gucu': '101-125 BG',\n",
    "    'Renk': 'Siyah',\n",
    "    'Kasa Tipi': 'Hatchback 5 Kapı',\n",
    "    'Kimden': 'Sahibinden',\n",
    "    'Durum': 'İkinci El',\n",
    "    'Km': 60000,\n",
    "}\n",
    "\n",
    "dummy_data_df = pd.DataFrame([dummy_data])  # Convert to DataFrame\n",
    "dummy_X = preprocessor.transform(dummy_data_df)\n",
    "\n",
    "prediction = rf.predict(dummy_X)\n",
    "\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
